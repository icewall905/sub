[general]
source_language = english
target_language = danish
context_size_before = 10
context_size_after = 10
use_deepl = false
use_google = true
use_libretranslate = true
use_mymemory = true
host = 127.0.0.1
port = 5000
temperature = 0.2

[translation]
# Configure the service priority (comma-separated list)
# Services will be tried in this order
service_priority = deepl,google,libretranslate,mymemory

# Retry settings for translation services
max_retries = 3
base_delay = 2

[logging]
file_enabled = true
log_file = translator.log
max_size_mb = 5
backup_count = 2

[ollama]
enabled = true
server_url = http://10.0.10.23:11434
endpoint = /api/generate
model = gemma3:12b
# Performance settings for Ollama
num_gpu = 1      # Number of GPUs to use (increase for multi-GPU systems)
num_thread = 4   # Number of threads to use for computation
use_mmap = true  # Memory-map the model (usually improves performance)
use_mlock = true # Lock the model in RAM (prevents swapping to disk)

[openai]
enabled = false
api_key = YOUR_OPENAI_KEY
api_base_url = https://api.openai.com/v1
model = gpt-3.5-turbo

[deepl]
enabled = false
api_key = YOUR_DEEPL_API_KEY
api_url = https://api-free.deepl.com/v2/translate

[libretranslate]
api_url = https://libretranslate.de/translate

[agent_critic]
enabled = false
temperature = 0.2

[multi_critic]
enabled = false
num_passes = 2

[critic_pass_1]
enabled = false
type = grammar
temperature = 0.2
description = Grammar Critic - focuses on improving grammar and syntax

[critic_pass_2]
enabled = false
type = cultural
temperature = 0.2
description = Cultural Critic - focuses on improving idioms and cultural references

[critic_pass_3]
enabled = false
type = consistency
temperature = 0.2
description = Consistency Critic - focuses on terminology consistency across subtitle lines
